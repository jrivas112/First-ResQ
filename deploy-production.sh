#!/bin/bash
# Production deployment script for QHelper AI

echo "ğŸš€ Deploying QHelper AI in Production Mode..."

# Stop any running development containers
echo "ğŸ“¦ Stopping existing containers..."
docker compose down

# Remove development volumes and build cache
echo "ğŸ§¹ Cleaning up development artifacts..."
docker system prune -f
docker volume prune -f

# Build production images
echo "ğŸ—ï¸ Building production images..."
docker compose build --no-cache

# Start production services
echo "ğŸŒŸ Starting production services..."
docker compose up -d

# Wait for services to start
echo "â³ Waiting for services to initialize..."
sleep 30

# Download optimal model for production
echo "ğŸ¤– Setting up AI model..."
docker exec ollama ollama pull qwen2:1.5b

# Check service status
echo "ğŸ” Checking service status..."
docker compose ps

echo ""
echo "âœ… Production deployment complete!"
echo ""
echo "ğŸŒ Frontend (Nginx): http://localhost"
echo "ğŸ”§ Ollama WebUI: http://localhost:8080"
echo "ğŸ“Š Backend API (internal): http://backend:8000"
echo ""
echo "ğŸ“ Note: Backend is now only accessible through Nginx proxy"
echo "ğŸ”’ Production optimizations enabled: compression, caching, security headers"
